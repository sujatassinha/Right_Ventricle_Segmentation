{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the necessary libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "import scipy.ndimage\n",
    "import IPython\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import optimizers\n",
    "import sklearn.model_selection\n",
    "import tensorflow.keras.backend as K\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/kiara/Desktop/CMR_Metric_Calculator/Dataset_Segmentation/'\n",
    "train_img_dir = os.path.join(base_dir, 'PNG_images/')\n",
    "train_label_dir = os.path.join(base_dir, 'PNG_labels/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtaining the training image (and corresponding label (masks)) file names as a list\n",
    "train_img_fname = os.listdir(train_img_dir)\n",
    "train_label_fname = train_img_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffling the image list randomply and saving it\n",
    "train_img_fnames = random.sample(train_img_fname, len(train_img_fname))\n",
    "train_label_fnames = train_img_fnames\n",
    "print(len(train_label_fnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset, test_dataset = sklearn.model_selection.train_test_split(train_img_fnames, test_size=0.1)\n",
    "train_img_fnames = training_dataset\n",
    "train_label_fnames = train_img_fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_fnames = test_dataset\n",
    "test_label_fnames = test_img_fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "IMG_CHANNEL = 1\n",
    "IMG_CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_img_fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "print(len(train_img_fnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an array of the same dimension as the input images\n",
    "X_train = np.zeros((2*len(train_img_fnames), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNEL), dtype = np.float32)\n",
    "Y_train = np.zeros((2*len(train_img_fnames), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Resizing train images\")\n",
    "from numpy import asarray\n",
    "from PIL import Image\n",
    "for n, id_ in tqdm(enumerate(train_img_fnames), total=len(train_img_fnames)):\n",
    "    n=n*2\n",
    "    img = imread(train_img_dir + id_) # read the image\n",
    "    pixels=asarray(img).astype('float32')\n",
    "    pixels = resize(pixels, (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNEL), mode = 'constant', preserve_range = True)\n",
    "    # convert from integers to floats\n",
    "    pixels = pixels.astype('float32')\n",
    "    # normalize to the range 0-1\n",
    "    pixels /= 255.0\n",
    "    # confirm the normalization\n",
    "    X_train[n] = pixels.astype('float32')\n",
    "    \n",
    "     # rotate only\n",
    "    img = imread(train_img_dir + id_) # read the image\n",
    "    r_img = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
    "    pixels1=asarray(r_img).astype('float32')\n",
    "    pixels1 = resize(pixels1, (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNEL), mode = 'constant', preserve_range = True)\n",
    "    # convert from integers to floats\n",
    "    pixels1 = pixels1.astype('float32')\n",
    "    # normalize to the range 0-1\n",
    "    pixels1 /= 255.0\n",
    "    # confirm the normalization\n",
    "    X_train[n+1] = pixels1.astype('float32')\n",
    "    '''\n",
    "    img = imread(train_img_dir + id_) # read the image\n",
    "    r_img = cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "    pixels1=asarray(r_img).astype('float32')\n",
    "    pixels1 = resize(pixels1, (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNEL), mode = 'constant', preserve_range = True)\n",
    "    # convert from integers to floats\n",
    "    pixels1 = pixels1.astype('float32')\n",
    "    # normalize to the range 0-1\n",
    "    pixels1 /= 255.0\n",
    "    # confirm the normalization\n",
    "    X_train[n+2] = pixels1.astype('float32')\n",
    "    \n",
    "    # rotate and CLAHE\n",
    "    img = cv2.imread((train_img_dir + id_), IMG_CHANNEL) # read the image\n",
    "    # rotate the image\n",
    "    r_img = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
    "    #Converting image to LAB Color so CLAHE can be applied to the luminance channel\n",
    "    lab_img= cv2.cvtColor(r_img, cv2.COLOR_BGR2LAB)\n",
    "    #Splitting the LAB image to L, A and B channels, respectively\n",
    "    l, a, b = cv2.split(lab_img)\n",
    "    #Apply histogram equalization to the L channel\n",
    "    equ = cv2.equalizeHist(l)\n",
    "    #Combine the Hist. equalized L-channel back with A and B channels\n",
    "    updated_lab_img1 = cv2.merge((equ,a,b))\n",
    "    #Apply CLAHE to L channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "    clahe_img = clahe.apply(l)\n",
    "    #Combine the CLAHE enhanced L-channel back with A and B channels\n",
    "    updated_lab_img2 = cv2.merge((clahe_img,a,b))\n",
    "    #Convert LAB image back to color (RGB)\n",
    "    CLAHE_img = cv2.cvtColor(updated_lab_img2, cv2.COLOR_LAB2BGR)\n",
    "    pixels=asarray(CLAHE_img).astype('float32')\n",
    "    pixels = resize(pixels, (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNEL), mode = 'constant', preserve_range = True)\n",
    "    # convert from integers to floats\n",
    "    pixels = pixels.astype('float32')\n",
    "    # normalize to the range 0-1\n",
    "    pixels /= 255.0\n",
    "    X_train[n+3] = pixels.astype('float32')'''\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    '''# Remove comments to perform Augmentation\n",
    "    #print(\"-----------------------CLAHE and ROTATE------------------\")\n",
    "    img = cv2.imread((train_img_dir + id_), IMG_CHANNEL) # read the image\n",
    "    # rotate the image\n",
    "    r_img = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
    "    #Converting image to LAB Color so CLAHE can be applied to the luminance channel\n",
    "    lab_img= cv2.cvtColor(r_img, cv2.COLOR_BGR2LAB)\n",
    "    #Splitting the LAB image to L, A and B channels, respectively\n",
    "    l, a, b = cv2.split(lab_img)\n",
    "    #Apply histogram equalization to the L channel\n",
    "    equ = cv2.equalizeHist(l)\n",
    "    #Combine the Hist. equalized L-channel back with A and B channels\n",
    "    updated_lab_img1 = cv2.merge((equ,a,b))\n",
    "    #Apply CLAHE to L channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "    clahe_img = clahe.apply(l)\n",
    "    #Combine the CLAHE enhanced L-channel back with A and B channels\n",
    "    updated_lab_img2 = cv2.merge((clahe_img,a,b))\n",
    "    #Convert LAB image back to color (RGB)\n",
    "    CLAHE_img = cv2.cvtColor(updated_lab_img2, cv2.COLOR_LAB2BGR)\n",
    "    pixels=asarray(CLAHE_img).astype('float32')\n",
    "    pixels = resize(pixels, (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNEL), mode = 'constant', preserve_range = True)\n",
    "    # convert from integers to floats\n",
    "    pixels = pixels.astype('float32')\n",
    "    # normalize to the range 0-1\n",
    "    pixels /= 255.0\n",
    "    X_train[n+3] = pixels.astype('float32')'''\n",
    "\n",
    "    '''\n",
    "    #print(\"-----------------------CLAHE ONLY ------------------\")\n",
    "    img = cv2.imread((train_img_dir + id_), IMG_CHANNEL) # read the image\n",
    "    # rotate the image\n",
    "    r_img = img\n",
    "    #Converting image to LAB Color so CLAHE can be applied to the luminance channel\n",
    "    lab_img= cv2.cvtColor(r_img, cv2.COLOR_BGR2LAB)\n",
    "    #Splitting the LAB image to L, A and B channels, respectively\n",
    "    l, a, b = cv2.split(lab_img)\n",
    "    #Apply histogram equalization to the L channel\n",
    "    equ = cv2.equalizeHist(l)\n",
    "    #Combine the Hist. equalized L-channel back with A and B channels\n",
    "    updated_lab_img1 = cv2.merge((equ,a,b))\n",
    "    #Apply CLAHE to L channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "    clahe_img = clahe.apply(l)\n",
    "    #Combine the CLAHE enhanced L-channel back with A and B channels\n",
    "    updated_lab_img2 = cv2.merge((clahe_img,a,b))\n",
    "    #Convert LAB image back to color (RGB)\n",
    "    CLAHE_img = cv2.cvtColor(updated_lab_img2, cv2.COLOR_LAB2BGR)\n",
    "    pixels=asarray(CLAHE_img).astype('float32')\n",
    "    pixels = resize(pixels, (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNEL), mode = 'constant', preserve_range = True)\n",
    "    # convert from integers to floats\n",
    "    pixels = pixels.astype('float32')\n",
    "    # normalize to the range 0-1\n",
    "    pixels /= 255.0\n",
    "    X_train[n+2] = pixels.astype('float32')\n",
    "    '''\n",
    "    '''#print(\"-----------------------CLAHE AND ROTATE COUNTER ONLY------------------\")\n",
    "    img = cv2.imread((train_img_dir + id_), 1) # read the image\n",
    "    # rotate the image\n",
    "    r_img = cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "    #Converting image to LAB Color so CLAHE can be applied to the luminance channel\n",
    "    lab_img= cv2.cvtColor(r_img, cv2.COLOR_BGR2LAB)\n",
    "    #Splitting the LAB image to L, A and B channels, respectively\n",
    "    l, a, b = cv2.split(lab_img)\n",
    "    #Apply histogram equalization to the L channel\n",
    "    equ = cv2.equalizeHist(l)\n",
    "    #Combine the Hist. equalized L-channel back with A and B channels\n",
    "    updated_lab_img1 = cv2.merge((equ,a,b))\n",
    "    #Apply CLAHE to L channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "    clahe_img = clahe.apply(l)\n",
    "    #Combine the CLAHE enhanced L-channel back with A and B channels\n",
    "    updated_lab_img2 = cv2.merge((clahe_img,a,b))\n",
    "    #Convert LAB image back to color (RGB)\n",
    "    CLAHE_img = cv2.cvtColor(updated_lab_img2, cv2.COLOR_LAB2BGR)\n",
    "    pixels=asarray(CLAHE_img).astype('float32')\n",
    "    pixels = resize(pixels, (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNEL), mode = 'constant', preserve_range = True)\n",
    "    # convert from integers to floats\n",
    "    pixels = pixels.astype('float32')\n",
    "    # normalize to the range 0-1\n",
    "    pixels /= 255.0\n",
    "    X_train[n+2] = pixels.astype('float32')'''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Resizing train images\")\n",
    "from numpy import asarray\n",
    "from PIL import Image\n",
    "for n, id_ in tqdm(enumerate(train_img_fnames), total=len(train_img_fnames)):\n",
    "    n=n*2\n",
    "    img = imread(train_label_dir + id_) # read the image\n",
    "    pixels=asarray(img).astype('float32')\n",
    "    pixels = resize(pixels, (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), mode = 'constant', preserve_range = True)\n",
    "    # convert from integers to floats\n",
    "    pixels = pixels.astype('float32')\n",
    "    # normalize to the range 0-1\n",
    "    pixels /= 255.0\n",
    "    Y_train[n] = pixels.astype('float32')\n",
    "    \n",
    "     #clahe and rotate\n",
    "    img = imread(train_label_dir + id_) # read the image\n",
    "    r_img = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
    "    pixels1=asarray(r_img).astype('float32')\n",
    "    pixels1 = resize(pixels1, (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), mode = 'constant', preserve_range = True)\n",
    "    # convert from integers to floats\n",
    "    pixels1 = pixels1.astype('float32')\n",
    "    # normalize to the range 0-1\n",
    "    pixels1 /= 255.0\n",
    "    # confirm the normalization\n",
    "    Y_train[n+1] = pixels1.astype('float32')\n",
    "    '''\n",
    "    # clahe and rotate counter\n",
    "    img = imread(train_label_dir + id_) # read the image\n",
    "    r_img = cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "    pixels1=asarray(r_img).astype('float32')\n",
    "    pixels1 = resize(pixels1, (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), mode = 'constant', preserve_range = True)\n",
    "    # convert from integers to floats\n",
    "    pixels1 = pixels1.astype('float32')\n",
    "    # normalize to the range 0-1\n",
    "    pixels1 /= 255.0\n",
    "    # confirm the normalization\n",
    "    Y_train[n+2] = pixels1.astype('float32')\n",
    "    \n",
    "    Y_train[n+3] = Y_train[n+1]'''\n",
    "    '''\n",
    "    # clahe only\n",
    "    #Y_train[n+2] = Y_train[n]'''\n",
    "    \n",
    "    '''# clahe and rotate counter\n",
    "    img = imread(train_label_dir + id_) # read the image\n",
    "    r_img = cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "    pixels1=asarray(r_img).astype('float32')\n",
    "    pixels1 = resize(pixels1, (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), mode = 'constant', preserve_range = True)\n",
    "    # convert from integers to floats\n",
    "    pixels1 = pixels1.astype('float32')\n",
    "    # normalize to the range 0-1\n",
    "    pixels1 /= 255.0\n",
    "    # confirm the normalization\n",
    "    Y_train[n+2] = pixels1.astype('float32')'''\n",
    "    \n",
    "    #Y_train[n+3] = Y_train[n+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting an image\n",
    "seed = 17\n",
    "np.random.seed = seed\n",
    "image_x = random.randint(0, len(train_img_fnames)) # generate a random number between 0 and length of training ids\n",
    "imshow(np.squeeze(X_train[image_x]))\n",
    "#plt.savefig(\"image.pdf\", format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(np.squeeze(Y_train[image_x]))\n",
    "#plt.savefig(\"label.pdf\", format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.zeros((len(test_img_fnames), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNEL), dtype = np.float32)\n",
    "sizes_test = []\n",
    "print(\"Resizing test images\")\n",
    "for n, id_ in tqdm(enumerate(test_img_fnames), total=len(test_img_fnames)):\n",
    "    path = base_dir\n",
    "    img = imread(train_img_dir + id_) # read the image\n",
    "    # Uncomment to test on HELIX Dataset\n",
    "    #img = imread('/media/kiara/My Passport/HELIX/image/' + id_)\n",
    "    pixels=asarray(img).astype('float32')\n",
    "    pixels = resize(pixels, (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNEL), mode = 'constant', preserve_range = True)\n",
    "    \n",
    "    # convert from integers to floats\n",
    "    pixels = pixels.astype('float32')\n",
    "    \n",
    "    # normalize to the range 0-1\n",
    "    pixels /= 255.0\n",
    "    X_test[n] = pixels.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = np.zeros((len(test_label_fnames), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype = np.float32)\n",
    "print(\"Resizing test images\")\n",
    "from numpy import asarray\n",
    "from PIL import Image\n",
    "for n, id_ in tqdm(enumerate(test_img_fnames), total=len(test_img_fnames)):\n",
    "    #path = base_dir\n",
    "    img = imread(train_label_dir + id_) # read the image\n",
    "    #img = imread('/media/kiara/My Passport/HELIX/label/ShortAxis/' + id_)\n",
    "    pixels=asarray(img).astype('float32')\n",
    "    pixels = resize(pixels, (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), mode = 'constant', preserve_range = True)\n",
    "    \n",
    "    # convert from integers to floats\n",
    "    pixels = pixels.astype('float32')\n",
    "    \n",
    "    # normalize to the range 0-1\n",
    "    pixels /= 255.0\n",
    "    Y_test[n] = pixels.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 17\n",
    "np.random.seed = seed\n",
    "image_x = random.randint(0, len(test_img_fnames)) # generate a random number between 0 and length of training ids\n",
    "imshow(np.squeeze(X_test[image_x]))\n",
    "#plt.savefig(\"image.pdf\", format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(np.squeeze(Y_test[image_x]))\n",
    "#plt.savefig(\"label.pdf\", format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics and Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_coef(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n",
    "    union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n",
    "    iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n",
    "    return iou\n",
    "\n",
    "def precision(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DC(y_true, y_pred, smooth=1):\n",
    "    \"\"\"\n",
    "    Dice = (2*|X & Y|)/ (|X|+ |Y|)\n",
    "         =  2*sum(|A*B|)/(sum(A^2)+sum(B^2))\n",
    "    ref: https://arxiv.org/pdf/1606.04797v1.pdf\n",
    "    \"\"\"\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    return (2. * intersection + smooth) / (K.sum(K.square(y_true),-1) + K.sum(K.square(y_pred),-1) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1-DC(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages necessary for model training\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "import scipy.ndimage\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "import IPython\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from numpy import asarray\n",
    "from PIL import Image\n",
    "import sklearn.model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "IMG_CHANNEL = 1\n",
    "IMG_CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining input layer\n",
    "inputs = tf.keras.layers.Input((IMG_WIDTH, IMG_HEIGHT, IMG_CHANNEL))\n",
    "# pixels to floating point numbers\n",
    "s = tf.keras.layers.Lambda(lambda x: (x/255))(inputs)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL 1 (Unet with Dropout Layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n",
    "c1 = tf.keras.layers.Dropout(0.5)(c1)\n",
    "c1 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
    "p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "c2 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
    "c2 = tf.keras.layers.Dropout(0.5)(c2)\n",
    "c2 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
    "p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
    " \n",
    "c3 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
    "c3 = tf.keras.layers.Dropout(0.5)(c3)\n",
    "c3 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
    "p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
    " \n",
    "c4 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
    "c4 = tf.keras.layers.Dropout(0.5)(c4)\n",
    "c4 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
    "p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
    " \n",
    "c5 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
    "c5 = tf.keras.layers.Dropout(0.5)(c5)\n",
    "c5 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
    "c5 = tf.keras.layers.Dropout(0.5)(c5)\n",
    "\n",
    "# Expansion Path\n",
    "u6 = tf.keras.layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "u6 = tf.keras.layers.concatenate([u6, c4])\n",
    "c6 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "c6 = tf.keras.layers.Dropout(0.5)(c6)\n",
    "c6 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
    " \n",
    "u7 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "u7 = tf.keras.layers.concatenate([u7, c3])\n",
    "c7 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "c7 = tf.keras.layers.Dropout(0.5)(c7)\n",
    "c7 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
    " \n",
    "u8 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "u8 = tf.keras.layers.concatenate([u8, c2])\n",
    "c8 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "c8 = tf.keras.layers.Dropout(0.5)(c8)\n",
    "c8 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
    " \n",
    "u9 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\n",
    "c9 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
    "c9 = tf.keras.layers.Dropout(0.5)(c9)\n",
    "c9 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
    "\n",
    "outputs = tf.keras.layers.Conv2D(3, (1,1), activation='sigmoid')(c9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "opt = keras.optimizers.Adam(learning_rate=0.1)\n",
    "model.compile(optimizer=opt, loss=tf.keras.losses.BinaryCrossentropy(), metrics=[DC, iou_coef, 'acc', precision, recall])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model checkpoint\n",
    "checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath='/home/kiara/Desktop/CMR_Metric_Calculator/UNET_WITH_2000RERUN.h5', verbose = 2, save_weights_only = True)\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience = 50, monitor = 'val_loss'),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir = 'Log_UNET_WITH_2000RERUN')\n",
    "]\n",
    "# change name to 2000RERUNAug\n",
    "\n",
    "# FIT MODEL\n",
    "results = model.fit(X_train, Y_train, validation_split = 0.1, batch_size = 4, epochs = 150, callbacks=callbacks)\n",
    "\n",
    "model.save('model_UNET_WITH_2000RERUN')\n",
    "model.save('model_UNET_WITH_2000RERUN.h5')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, Y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL 2 (Unet without Dropout Layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Contraction path\n",
    "c1 = tf.keras.layers.Conv2D(32, (3, 3), activation='tanh', kernel_initializer='he_normal', padding='same')(s)\n",
    "#c1 = tf.keras.layers.Dropout(0.5)(c1)\n",
    "c1 = tf.keras.layers.Conv2D(32, (3, 3), activation='tanh', kernel_initializer='he_normal', padding='same')(c1)\n",
    "p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "c2 = tf.keras.layers.Conv2D(64, (3, 3), activation='tanh', kernel_initializer='he_normal', padding='same')(p1)\n",
    "#c2 = tf.keras.layers.Dropout(0.5)(c2)\n",
    "c2 = tf.keras.layers.Conv2D(64, (3, 3), activation='tanh', kernel_initializer='he_normal', padding='same')(c2)\n",
    "p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
    " \n",
    "c3 = tf.keras.layers.Conv2D(128, (3, 3), activation='tanh', kernel_initializer='he_normal', padding='same')(p2)\n",
    "#c3 = tf.keras.layers.Dropout(0.4)(c3)\n",
    "c3 = tf.keras.layers.Conv2D(128, (3, 3), activation='tanh', kernel_initializer='he_normal', padding='same')(c3)\n",
    "p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
    " \n",
    "c4 = tf.keras.layers.Conv2D(256, (3, 3), activation='tanh', kernel_initializer='he_normal', padding='same')(p3)\n",
    "#c4 = tf.keras.layers.Dropout(0.5)(c4)\n",
    "c4 = tf.keras.layers.Conv2D(256, (3, 3), activation='tanh', kernel_initializer='he_normal', padding='same')(c4)\n",
    "p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
    " \n",
    "c5 = tf.keras.layers.Conv2D(512, (3, 3), activation='tanh', kernel_initializer='he_normal', padding='same')(p4)\n",
    "#c5 = tf.keras.layers.Dropout(0.4)(c5)\n",
    "c5 = tf.keras.layers.Conv2D(512, (3, 3), activation='tanh', kernel_initializer='he_normal', padding='same')(c5)\n",
    "#c5 = tf.keras.layers.Dropout(0.5)(c5)\n",
    "\n",
    "# Expansion Path\n",
    "u6 = tf.keras.layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "u6 = tf.keras.layers.concatenate([u6, c4])\n",
    "c6 = tf.keras.layers.Conv2D(256, (3, 3), activation='tanh', kernel_initializer='he_normal', padding='same')(u6)\n",
    "#c6 = tf.keras.layers.Dropout(0.4)(c6)\n",
    "c6 = tf.keras.layers.Conv2D(512, (3, 3), activation='tanh', kernel_initializer='he_normal', padding='same')(c6)\n",
    " \n",
    "u7 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "u7 = tf.keras.layers.concatenate([u7, c3])\n",
    "c7 = tf.keras.layers.Conv2D(128, (3, 3), activation='tanh', kernel_initializer='he_normal', padding='same')(u7)\n",
    "#c7 = tf.keras.layers.Dropout(0.5)(c7)\n",
    "c7 = tf.keras.layers.Conv2D(128, (3, 3), activation='tanh', kernel_initializer='he_normal', padding='same')(c7)\n",
    " \n",
    "u8 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "u8 = tf.keras.layers.concatenate([u8, c2])\n",
    "c8 = tf.keras.layers.Conv2D(64, (3, 3), activation='tanh', kernel_initializer='he_normal', padding='same')(u8)\n",
    "#c8 = tf.keras.layers.Dropout(0.5)(c8)\n",
    "c8 = tf.keras.layers.Conv2D(64, (3, 3), activation='tanh', kernel_initializer='he_normal', padding='same')(c8)\n",
    " \n",
    "u9 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\n",
    "c9 = tf.keras.layers.Conv2D(32, (3, 3), activation='tanh', kernel_initializer='he_normal', padding='same')(u9)\n",
    "#c9 = tf.keras.layers.Dropout(0.4)(c9)\n",
    "c9 = tf.keras.layers.Conv2D(32, (3, 3), activation='tanh', kernel_initializer='he_normal', padding='same')(c9)\n",
    "\n",
    "outputs = tf.keras.layers.Conv2D(3, (1,1), activation='sigmoid')(c9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "opt = keras.optimizers.Adam(learning_rate=0.1)\n",
    "model.compile(optimizer=opt, loss=tf.keras.losses.BinaryCrossentropy(), metrics=[DC, iou_coef, 'acc', precision, recall])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model checkpoint\n",
    "checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath='/home/kiara/Desktop/CMR_Metric_Calculator/UNET_WITHOUT_10000AugRERUN.h5', verbose = 2, save_weights_only = True)\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience = 50, monitor = 'val_loss'),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir = 'Log_UNET_WITHOUT_10000AugRERUN')\n",
    "]\n",
    "\n",
    "\n",
    "# FIT MODEL\n",
    "results = model.fit(X_train, Y_train, validation_split = 0.1, batch_size = 4, epochs = 150, callbacks=callbacks)\n",
    "\n",
    "model.save('model_UNET_WITHOUT_10000AugRERUN')\n",
    "model.save('model_UNET_WITHOUT_10000AugRERUN.h5')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, Y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL 3 (ResUnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken directly from the original implementation https://arxiv.org/pdf/1711.10684.pdf\n",
    "def bn_act(x, act=True):\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    if act == True:\n",
    "        x = tf.keras.layers.Activation(\"tanh\")(x)\n",
    "        #x = tf.keras.layers.Activation(\"sigmoid\")(x)\n",
    "    return x\n",
    "\n",
    "def conv_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
    "    conv = bn_act(x)\n",
    "    conv = tf.keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides)(conv)\n",
    "    return conv\n",
    "\n",
    "def stem(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
    "    conv = tf.keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides)(x)\n",
    "    conv = conv_block(conv, filters, kernel_size=kernel_size, padding=padding, strides=strides)\n",
    "    \n",
    "    shortcut = tf.keras.layers.Conv2D(filters, kernel_size=(1, 1), padding=padding, strides=strides)(x)\n",
    "    shortcut = bn_act(shortcut, act=False)\n",
    "    \n",
    "    output = tf.keras.layers.Add()([conv, shortcut])\n",
    "    return output\n",
    "\n",
    "def residual_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
    "    res = conv_block(x, filters, kernel_size=kernel_size, padding=padding, strides=strides)\n",
    "    res = conv_block(res, filters, kernel_size=kernel_size, padding=padding, strides=1)\n",
    "    \n",
    "    shortcut = tf.keras.layers.Conv2D(filters, kernel_size=(1, 1), padding=padding, strides=strides)(x)\n",
    "    shortcut = bn_act(shortcut, act=False)\n",
    "    \n",
    "    output = tf.keras.layers.Add()([shortcut, res])\n",
    "    return output\n",
    "\n",
    "def upsample_concat_block(x, xskip):\n",
    "    u = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
    "    c = tf.keras.layers.concatenate([u, xskip])\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken directly from the original implementation https://arxiv.org/pdf/1711.10684.pdf\n",
    "def ResUNet():\n",
    "    \n",
    "    #f = [24, 48, 96, 192, 384]\n",
    "    #f = [8, 16, 32, 64, 128]\n",
    "    #f = [64, 128, 256, 512, 1024]\n",
    "    #f = [8, 16, 32, 64, 128]#1st\n",
    "    # 16 2nd then 4 3rd\n",
    "    f = [4, 8, 16, 32, 64]\n",
    "    \n",
    "    #f = [32, 64, 128, 256, 512]\n",
    "    inputs = keras.layers.Input((256, 256, 1))\n",
    "    \n",
    "    ## Encoder\n",
    "    e0 = inputs\n",
    "    e1 = stem(e0, f[0])\n",
    "    e2 = residual_block(e1, f[1], strides=2)\n",
    "    e3 = residual_block(e2, f[2], strides=2)\n",
    "    e4 = residual_block(e3, f[3], strides=2)\n",
    "    e5 = residual_block(e4, f[4], strides=2)\n",
    "    \n",
    "    ## Bridge\n",
    "    b0 = conv_block(e5, f[4], strides=1)\n",
    "    b1 = conv_block(b0, f[4], strides=1)\n",
    "    \n",
    "    ## Decoder\n",
    "    u1 = upsample_concat_block(b1, e4)\n",
    "    d1 = residual_block(u1, f[4])\n",
    "    \n",
    "    u2 = upsample_concat_block(d1, e3)\n",
    "    d2 = residual_block(u2, f[3])\n",
    "    \n",
    "    u3 = upsample_concat_block(d2, e2)\n",
    "    d3 = residual_block(u3, f[2])\n",
    "    \n",
    "    u4 = upsample_concat_block(d3, e1)\n",
    "    d4 = residual_block(u4, f[1])\n",
    "    \n",
    "    outputs = keras.layers.Conv2D(3, (1, 1), padding=\"same\", activation=\"sigmoid\")(d4)\n",
    "    model = keras.models.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResUNet()\n",
    "from keras.utils import to_categorical\n",
    "opt = keras.optimizers.Adam(learning_rate=0.1)\n",
    "model.compile(optimizer=opt, loss=tf.keras.losses.BinaryCrossentropy(), metrics=[DC, iou_coef, 'acc', precision, recall])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model checkpoint\n",
    "checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath='/home/kiara/Desktop/CMR_Metric_Calculator/RESUNET_10000.h5', verbose = 2, save_weights_only = True)\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience = 50, monitor = 'val_loss'),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir = 'Log_RESUNET_10000')\n",
    "]\n",
    "\n",
    "\n",
    "# FIT MODEL\n",
    "results = model.fit(X_train, Y_train, validation_split = 0.1, batch_size = 4, epochs = 150, callbacks=callbacks)\n",
    "\n",
    "model.save('model_RESUNET_10000')\n",
    "model.save('model_RESUNET_10000.h5')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, Y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL 4 (FCN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n",
    "c1 = tf.keras.layers.Dropout(0.5)(c1)\n",
    "c1 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
    "p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "c2 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
    "c2 = tf.keras.layers.Dropout(0.5)(c2)\n",
    "c2 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
    "p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
    " \n",
    "c3 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
    "c3 = tf.keras.layers.Dropout(0.5)(c3)\n",
    "c3 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
    "p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
    " \n",
    "c4 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
    "c4 = tf.keras.layers.Dropout(0.5)(c4)\n",
    "c4 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
    "p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
    " \n",
    "c5 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
    "c5 = tf.keras.layers.Dropout(0.5)(c5)\n",
    "c5 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
    "c5 = tf.keras.layers.Dropout(0.5)(c5)\n",
    "\n",
    "u6 = tf.keras.layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "c6 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "c6 = tf.keras.layers.Dropout(0.5)(c6)\n",
    "c6 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
    " \n",
    "u7 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "c7 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "c7 = tf.keras.layers.Dropout(0.5)(c7)\n",
    "c7 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
    " \n",
    "u8 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "u8 = tf.keras.layers.concatenate([u8, c2])\n",
    "c8 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "c8 = tf.keras.layers.Dropout(0.5)(c8)\n",
    "c8 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
    " \n",
    "u9 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\n",
    "c9 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
    "c9 = tf.keras.layers.Dropout(0.5)(c9)\n",
    "c9 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "outputs = tf.keras.layers.Conv2D(3, (1,1), activation='sigmoid')(c9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "opt = keras.optimizers.Adam(learning_rate=0.1)\n",
    "model.compile(optimizer=opt, loss=tf.keras.losses.BinaryCrossentropy(), metrics=[DC, iou_coef, 'acc', precision, recall])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model checkpoint\n",
    "checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath='/home/kiara/Desktop/CMR_Metric_Calculator/FCN_10000.h5', verbose = 2, save_weights_only = True)\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience = 50, monitor = 'val_loss'),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir = 'Log_FCN_10000')\n",
    "]\n",
    "\n",
    "\n",
    "# FIT MODEL\n",
    "results = model.fit(X_train, Y_train, validation_split = 0.1, batch_size = 4, epochs = 150, callbacks=callbacks)\n",
    "\n",
    "model.save('model_FCN_10000')\n",
    "model.save('model_FCN_10000.h5')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, Y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
